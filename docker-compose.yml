
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.0.1
    container_name: zookeeper
    env_file:
      - .env
    environment:
      ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_PORT}
    ports:
      - "${ZOOKEEPER_PORT}:${ZOOKEEPER_PORT}"
    volumes:
      - zookeeper-data:/var/lib/zookeeper/data

  kafka:
    image: confluentinc/cp-kafka:7.0.1
    container_name: kafka
    depends_on:
      - zookeeper
    env_file:
      - .env
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:${ZOOKEEPER_PORT}
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:${KAFKA_PORT}
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    ports:
      - "${KAFKA_PORT}:${KAFKA_PORT}"
    volumes:
      - kafka-data:/var/lib/kafka/data

  producer:
    build:
      context: .
      dockerfile: kafka_folder/Dockerfile
    container_name: producer
    depends_on:
      - kafka
    env_file:
      - .env
    environment:
      - KAFKA_BROKER_URL=kafka:${KAFKA_PORT}
    volumes:
      - .:/app
    command: >
      sh -c "
        echo 'Waiting for Kafka to be ready...' &&
        sleep 15 &&
        python entrypoint_fluxo_clima.py
      "

  spark-master:
    build:
      context: .
      dockerfile: spark_folder/Dockerfile
    container_name: spark-master
    hostname: spark-master
    env_file:
      - .env
    environment:
      - SPARK_MODE=master
    ports:
      - "${SPARK_MASTER_PORT}:${SPARK_MASTER_PORT}"
      - "${SPARK_MASTER_UI_PORT}:${SPARK_MASTER_UI_PORT}"
    volumes:
      - ./spark_folder:/app

  spark-worker:
    build:
      context: .
      dockerfile: spark_folder/Dockerfile
    container_name: spark-worker
    hostname: spark-worker
    depends_on:
      - spark-master
    env_file:
      - .env
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:${SPARK_MASTER_PORT}
      - SPARK_WORKER_MEMORY=${SPARK_WORKER_MEMORY}
      - SPARK_WORKER_CORES=${SPARK_WORKER_CORES}
      - SPARK_EXECUTOR_MEMORY=${SPARK_EXECUTOR_MEMORY}
      - SPARK_EXECUTOR_CORES=${SPARK_EXECUTOR_CORES}
    ports:
      - "${SPARK_WORKER_UI_PORT}:${SPARK_WORKER_UI_PORT}"
    volumes:
      - ./spark_folder:/app

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "${GRAFANA_PORT}:${GRAFANA_PORT}"
    env_file:
      - .env
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USERNAME}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
    volumes:
      - grafana-storage:/var/lib/grafana
    depends_on:
      - influxdb

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "${KAFKA_UI_PORT}:8080"
    env_file:
      - .env
    environment:
      - KAFKA_CLUSTERS_0_NAME=${KAFKA_UI_NAME}
      - KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS=kafka:${KAFKA_PORT}
    depends_on:
      - kafka

  influxdb:
    image: influxdb:2.7
    container_name: influxdb
    ports:
      - "${INFLUXDB_PORT}:${INFLUXDB_PORT}"
    volumes:
      - influxdb-storage:/var/lib/influxdb2
    env_file:
      - .env
    environment:
      - DOCKER_INFLUXDB_INIT_MODE=setup
      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}
      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PASSWORD}
      - DOCKER_INFLUXDB_INIT_ORG=${INFLUXDB_ORG}
      - DOCKER_INFLUXDB_INIT_BUCKET=${INFLUXDB_BUCKET}
      - DOCKER_INFLUXDB_INIT_ADMIN_TOKEN=${INFLUXDB_TOKEN}

networks:
  default:
    name: spark-network
    driver: bridge

volumes:
  zookeeper-data:
  kafka-data:
  grafana-storage:
  influxdb-storage:
